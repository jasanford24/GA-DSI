{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis: A track with a higher average billboard rank will remain on the billboard chart longer.\n",
    "\n",
    "If a track has a low average rank in the Billboard, it is highly unlikely to stay on the billboard for more than 19 weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "#Used to ignore annoying warnings.\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read in the data from the file.\n",
    "df = pd.read_csv('assets/billboard.csv', encoding='latin-1')\n",
    "flag = True\n",
    "\n",
    "#Renames the first 9 weeks so that I can then sort it easier later on.\n",
    "df.rename(columns={'x1st.week': 'x01st.week', \\\n",
    "                   'x2nd.week': 'x02nd.week', \\\n",
    "                  'x3rd.week': 'x03rd.week', \\\n",
    "                  'x4th.week': 'x04th.week', \\\n",
    "                  'x5th.week': 'x05th.week', \\\n",
    "                  'x6th.week': 'x06th.week', \\\n",
    "                  'x7th.week': 'x07th.week', \\\n",
    "                  'x8th.week': 'x08th.week', \\\n",
    "                  'x9th.week': 'x09th.week'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Function converting columns to INT or Float if there's a NaN\n",
    "def columnInt(ghost):\n",
    "    k=0\n",
    "    for y in ghost:\n",
    "        df[ghost[k]] = pd.to_numeric(df[ghost[k]], errors='coerce')\n",
    "        k+=1\n",
    "\n",
    "#Turns all * to NaN\n",
    "def replaceNulls(dang):\n",
    "    for y in dang:\n",
    "        for x in df[y]:\n",
    "            if x == '*':\n",
    "                return np.nan\n",
    "            else:\n",
    "                return x\n",
    "\n",
    "#Converts time into int(seconds).\n",
    "def timeSec():\n",
    "    j=0\n",
    "    for x in df['time']:\n",
    "        seconds = int(x[2:4])\n",
    "        seconds = seconds + int(x[0]) * 60\n",
    "        df['time'][j] = seconds\n",
    "        j+=1\n",
    "    columnInt(df.columns[3:4].values)\n",
    "\n",
    "#Converts unicode to string.\n",
    "def uniStr(awwheck):\n",
    "    j=0\n",
    "    p=0\n",
    "    for y in awwheck:\n",
    "        for x in df[awwheck[p]]:\n",
    "            df[awwheck[p]][j] = x.encode('ascii','ignore')\n",
    "            j+=1\n",
    "        p+=1\n",
    "        j=0\n",
    "\n",
    "#Combines R & B and R&B\n",
    "def genreFix():\n",
    "    j=0\n",
    "    for x in df['genre']:\n",
    "        if x == 'R & B':\n",
    "            df['genre'][j] = 'R&B'\n",
    "            j+=1\n",
    "        else:\n",
    "            j+=1\n",
    "\n",
    "\n",
    "#Adds the average rank of the track on the chart to the dataframe\n",
    "def add_rank():\n",
    "    track_rank_mean = []\n",
    "    for x in range(317):\n",
    "         track_rank_mean.append(np.mean(dftest[x][7:83]))\n",
    "\n",
    "    track_rank_mean = pd.Series(track_rank_mean).rename(\"Rank Average\")\n",
    "    track_rank_mean = track_rank_mean.to_frame().T\n",
    "\n",
    "\n",
    "#Adds the count of weeks the track was on the top 100 chart.\n",
    "def add_count():\n",
    "    test_list = []\n",
    "    relation_list = []\n",
    "    for x in range(317):\n",
    "        track_count = 0\n",
    "\n",
    "        for y in dftest[x][weeks].values.tolist():\n",
    "            if y > 0:\n",
    "                track_count+=1\n",
    "\n",
    "        test_list.append(track_count)\n",
    "    ghj = pd.Series(test_list).rename(\"Rank Count\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate a non-NDFrame object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-31972b701c44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mtrack_rank_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0madd_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mdftest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdftest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack_rank_mean\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0madd_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jesse/anaconda/lib/python2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, copy)\u001b[0m\n\u001b[1;32m    843\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                        copy=copy)\n\u001b[0m\u001b[1;32m    846\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jesse/anaconda/lib/python2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy)\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobjs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNDFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot concatenate a non-NDFrame object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0;31m# consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate a non-NDFrame object"
     ]
    }
   ],
   "source": [
    "#Flag is here to make sure I don't run this section more than once without reading in the CSV\n",
    "if flag == True:\n",
    "    #Runs the time into INT(seconds) function\n",
    "    timeSec()\n",
    "\n",
    "    #Stores the weeks columns in weeks\n",
    "    weeks = df.columns[7:83]\n",
    "    #Stores the genre, date.entered, and date.peaked into hk\n",
    "    hk = df.columns[4:7]\n",
    "    hj = df.columns[1:3]\n",
    "    \n",
    "    #Runs the replaceNulls function\n",
    "    replaceNulls(weeks)\n",
    "    \n",
    "    #Runs the column to INT function\n",
    "    columnInt(weeks)\n",
    "    \n",
    "    #Turns the column from Unicode to String\n",
    "    uniStr(hk)\n",
    "    uniStr(hj)\n",
    "    \n",
    "    #Runs the genre fix function.\n",
    "    genreFix()\n",
    "    \n",
    "    df['genre'] = df['genre'].astype(str)\n",
    "    \n",
    "    #Changes the format of the data and is the primary dataframe used.\n",
    "    dftest = df.T\n",
    "    track_rank_mean = []\n",
    "    add_rank()\n",
    "    dftest = pd.concat([dftest, track_rank_mean])\n",
    "    \n",
    "    add_count()\n",
    "    dftest = pd.concat([dftest, ghj.to_frame().T])\n",
    "    \n",
    "    flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to make a scatter plot.\n",
    "def scatter_graph(title, hjj, xlab, ylab):\n",
    "    ax = hjj.plot(x='Rank Count', y='Rank Average', kind='scatter', color='dodgerblue',\\\n",
    "                     figsize=(15,7), s=250, fontsize=20)\n",
    "    ax.set_title(title, fontsize=24, y=1.01)\n",
    "    ax.set_ylim(0,101)\n",
    "    ax.set_xlim(0,60)\n",
    "    ax.set_xlabel(xlab, fontsize=18)\n",
    "    ax.set_ylabel(ylab, fontsize=18)\n",
    "    ax.invert_yaxis();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Takes the Rank Count and Rank Average rows and puts it into a new DataFrame then graphs it.\n",
    "test_dff = dftest[83:85].T\n",
    "scatter_graph(\"Average Track Rank by Number of Weeks on Chart\", test_dff,\\\n",
    "              \"Number of Weeks on Chart\", \"Average Rank of Track on Chart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Stores the tracks with over 20 weeks on the chart into tester_dff\n",
    "tester_dff = test_dff[test_dff['Rank Count']>20]\n",
    "test_dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Stores the tracks with less than 21 weeks on the chart into teste_dff\n",
    "teste_dff = test_dff[test_dff['Rank Count']<=20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Found the average of the tracks above and below 20 weeks\n",
    "print np.mean(tester_dff['Rank Average'])\n",
    "print np.mean(teste_dff['Rank Average'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Calculated the number of tracks each genre had with over 20 weeks.\n",
    "dtestf = pd.concat([test_dff, df['genre'].to_frame()], axis=1)\n",
    "pam = dtestf[dtestf['Rank Count']>20]\n",
    "test_array = np.unique(pam['genre'], return_counts=True)\n",
    "genre_name = pd.Series(test_array[0]).rename(\"Names\")\n",
    "genre_number = pd.Series(test_array[1]).rename(\"Number\")\n",
    "\n",
    "testert = [genre_name, genre_number]\n",
    "genre_df = pd.DataFrame(testert).T\n",
    "genre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Graphed the above data into bar graph.\n",
    "ax = genre_df.plot(x='Names', y='Number', kind=\"bar\", color='dodgerblue',\\\n",
    "                 figsize=(15,7), fontsize=20)\n",
    "ax.set_title(\"Genres of Tracks on Chart Over 20 Weeks\", fontsize=24, y=1.01)\n",
    "ax.set_ylim(0,30)\n",
    "ax.set_xticklabels(test_array[0],rotation=45)\n",
    "ax.set_xlabel(\"Genres\", fontsize=18)\n",
    "ax.set_ylabel(\"Number of Tracks\", fontsize=18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testsdf = dftest[7:83]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#First graph I made with the data which showed a mysterious falling off around week 20\n",
    "ax = testsdf.plot(figsize=(15,7), fontsize=10, legend=False)\n",
    "\n",
    "ax.set_title(\"Tracks in Top 100\", fontsize=21, y=1.01)\n",
    "\n",
    "ax.set_xticklabels([int(y) for y in ax.get_xticks()])\n",
    "ax.set_ylim(0,100)\n",
    "\n",
    "ax.invert_yaxis();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hanks = []\n",
    "\n",
    "i=0\n",
    "for y in weeks:\n",
    "    for x in df[y]:\n",
    "        if x > 0:\n",
    "            i+=1\n",
    "    hanks.append(i)\n",
    "    i=0\n",
    "tanks = pd.Series(hanks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#graphed the track decay rate and found a large drop between weeks 19 and 20\n",
    "ax = tanks.plot(color='dodgerblue', figsize=(15,7), fontsize=20)\n",
    "ax.set_title(\"Track Fall Off Rate\", fontsize=25, y=1.01)\n",
    "ax.set_ylabel(\"Number of Tracks\", fontsize=20)\n",
    "ax.set_xlabel(\"Number of Weeks on Chart\", fontsize=20)\n",
    "ax.set_ylim(1,320);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Used a pivot_table to find the averages of each genre per week.\n",
    "t_hanks = pd.pivot_table(df, index=['genre'], values=weeks[0:20])\n",
    "t_hanks2 = t_hanks.iloc[:,:].T\n",
    "t_hanks2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pr = t_hanks2.columns[:]\n",
    "genre_average_on_chart = np.mean(t_hanks2[pr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Graphed the genre averages\n",
    "ax = genre_average_on_chart.plot(figsize=(15,7), kind=\"bar\", fontsize=10)\n",
    "\n",
    "ax.set_title(\"Average Rank of Genre on Billboard\", fontsize=21, y=1.01)\n",
    "ax.set_ylim(0,101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
